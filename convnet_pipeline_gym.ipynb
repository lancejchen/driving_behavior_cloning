{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some common CV function \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from time import time\n",
    "import csv\n",
    "import h5py\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduce some common used CV functions below\n",
    "They are not used in my model since it can eliminate important features and may cause model loss generalization ability. But use CV techniques properly can effectively reduce learning workload of a model and may get a same result with smaller model and smaller training dataset.\n",
    "\n",
    "Use them with cautious. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some common used CV functions\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\n",
    "    # filling pixels inside the polygon defined by \"vertices\" with the fill color\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    # returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len,\n",
    "                            maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "\n",
    "def detect_lane_line(image):\n",
    "    gray_img = grayscale(image)\n",
    "    blur_gray = gaussian_blur(gray_img, kernel_size=5)\n",
    "    edges = canny(blur_gray, low_threshold=50, high_threshold=150)\n",
    "    imshape = image.shape\n",
    "    vertices = np.array([[(100,imshape[0]),(480, 310), (490, 315), (900,imshape[0])]])\n",
    "    marked_edges = region_of_interest(edges, vertices)\n",
    "    line_img = hough_lines(marked_edges, rho=2, theta=(np.pi/180), threshold=15, min_line_len=40, max_line_gap=20)\n",
    "    final_image = weighted_img(line_img, image)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process images and corresponding angles and save them to a h5 file as training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv(csv_path, img_dir):\n",
    "    \"\"\" Read from the csv file, return image paths and their corresponding angles\n",
    "\n",
    "    :param str csv_path: Where is the input csv file\n",
    "    :param str img_dir: Where do images locate (images directory)\n",
    "\n",
    "    :return: (img_path, angle)\n",
    "        img_path:  (list) image paths get from csv file\n",
    "        angle: (list) corresponding angles from images from img_path\n",
    "    :rtype: tuple(list, list)\n",
    "\n",
    "    \"\"\"\n",
    "    img_path = []\n",
    "    angle = []\n",
    "    with open(csv_path, newline='') as f:\n",
    "        log_reader = csv.reader(f, delimiter=',')\n",
    "        for row in log_reader:\n",
    "            center_img = row[0]\n",
    "            loc = img_dir + center_img.split('/')[-1]\n",
    "            img_path.append(loc)\n",
    "            angle.append(row[3])\n",
    "    angle = np.array(angle, dtype=np.float32)\n",
    "    print(angle.dtype)\n",
    "    print('Is image path len same as angles? ', len(img_path) == angle.shape[0])\n",
    "    return img_path, angle\n",
    "\n",
    "\n",
    "# pre-process input images,\n",
    "def preprocess_img(img_path, height, width, channel):\n",
    "    \"\"\" pre-process images located in img_path parameter\n",
    "        by resizing them to desired shape then horizontally flip them to double the data size\n",
    "\n",
    "    :param list of str img_path: locations of all images in the list\n",
    "    :param int height: desired height\n",
    "    :param int width: desired width\n",
    "    :param int channel: desired color channel\n",
    "    :return: images with desired shape as a numpy array\n",
    "    :rtype: Numpy array\n",
    "    \"\"\"\n",
    "    start = time()\n",
    "    loop_time = time()\n",
    "    img_stack = np.zeros((1, height, width, channel))\n",
    "    for i, loc in enumerate(img_path):\n",
    "        img = mpimg.imread(loc)\n",
    "        img = img[54:]\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img_flip = cv2.flip(img, 1)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img_flip = np.expand_dims(img_flip, axis=0)\n",
    "        img_stack = np.concatenate((img_stack, img, img_flip))\n",
    "\n",
    "        del img, img_flip\n",
    "        if i % 500 == 0:\n",
    "            abc = time()\n",
    "            print(i, ' read and resize takes: ', abc - start, '500 diff is: ',abc - loop_time)\n",
    "            loop_time = abc\n",
    "    print('Whole process takes that long: ', time() - start)\n",
    "    img_stack = img_stack[1:]\n",
    "    return img_stack\n",
    "\n",
    "\n",
    "def save_to_h5(data_dict, h5_file):\n",
    "    f = h5py.File(h5_file)\n",
    "    for k, v in data_dict.items():\n",
    "        if k in f:  # if dataset already exists\n",
    "            dset = f[k]\n",
    "            ori_nb = f[k].shape[0]\n",
    "            added_nb = v.shape[0]\n",
    "            nb_after_resize = ori_nb + added_nb\n",
    "            dset.resize(nb_after_resize, axis=0)\n",
    "            dset[-added_nb:] = v\n",
    "        else:\n",
    "            max_shape = [None,]\n",
    "            for i in v.shape[1:]:\n",
    "                max_shape.append(i)\n",
    "            f.create_dataset(k, data=v, maxshape=max_shape)\n",
    "    f.flush()\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def save_preprocess_img(path, storage_path):\n",
    "    data_dict = {}\n",
    "    csv_path = path + 'driving_log.csv'\n",
    "    img_dir = path + 'IMG/'\n",
    "    img_paths, angles = read_csv(csv_path, img_dir)\n",
    "    img_stack = preprocess_img(img_paths, height=66, width=200, channel=3)\n",
    "\n",
    "    y = np.zeros(1)\n",
    "    for val in angles:\n",
    "        a1 = val\n",
    "        a2 = - a1\n",
    "        y = np.append(y, (a1, a2))\n",
    "    y = y[1:]\n",
    "    img_stack = img_stack.astype(np.int16)\n",
    "\n",
    "    for i in range(5):\n",
    "        img_stack, y = shuffle(img_stack, y, random_state=i)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(img_stack, y, test_size=0.2, random_state=43)\n",
    "\n",
    "    print('img_stack shape is: ', img_stack.shape)\n",
    "    print('angles list here: ', len(y))\n",
    "    data_dict = {'X_train': X_train, 'X_val': X_val, 'y_train': y_train, 'y_val': y_val}\n",
    "    save_to_h5(data_dict, storage_path)\n",
    "    del data_dict, y, img_stack, angles, X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take images from a training dataset directory and convert to specified h5 file \n",
    "dir_index = ['bridge_2', 'last_sandy']\n",
    "base_path = '../data/'\n",
    "h5_path = '../data/h5_storage.h5'\n",
    "path_list = [base_path + name + '/' for name in dir_index]\n",
    "for path in path_list:\n",
    "    save_preprocess_img(path, h5_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells above are for pre-processing training dataset and are not needed for tuning a new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine tune a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.io_utils import HDF5Matrix\n",
    "import h5py\n",
    "import json\n",
    "import gc\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch generator generates batch data from training h5 file.\n",
    "# The h5 file & its contents are built by ./image_angle_to_h5.py from data generated in simulator training mode.\n",
    "def batch_generator(path, X, y, batch_size=32):\n",
    "        nb_data = HDF5Matrix(path, X).shape[0]\n",
    "        i = 0\n",
    "        f = h5py.File(path)\n",
    "        X_train = f[X]\n",
    "        y_train = f[y]\n",
    "        while True:\n",
    "            start = (batch_size * i) % nb_data\n",
    "            end = batch_size * (i + 1) % nb_data\n",
    "            i += 1 \n",
    "            if end < start:\n",
    "                continue\n",
    "            yield (X_train[start:end], y_train[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My ConvNet model 0\n",
    "def get_model_0():\n",
    "    row, col, ch = 66, 200, 3  # camera format\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(row, col, ch),\n",
    "            output_shape=(row, col, ch)))\n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"valid\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My CNN model 1\n",
    "def get_model_1():\n",
    "    row, col, ch = 66, 200, 3\n",
    "\n",
    "    model = Sequential()\n",
    "    # normalize input image.\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "                     input_shape=(row, col, ch), output_shape=(row, col, ch)))\n",
    "\n",
    "    # convolution layers\n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"valid\"))\n",
    "\n",
    "    # flatten CNN layer for fc layers\n",
    "    model.add(Flatten())\n",
    "    # dropout for regularization usage\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "\n",
    "    # fc layers for regression\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My CNN model 2\n",
    "def get_model_2():\n",
    "    row, col, ch = 66, 200, 3  # camera format\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(row, col, ch),\n",
    "            output_shape=(row, col, ch)))\n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"valid\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 5 \n",
    "model = get_model_1()\n",
    "h5_path = '../data/p3_data.h5'\n",
    "batch_size = 128    # 32 is better, since it will have more weights updates, but 128 is used in this model.\n",
    "nb_train = HDF5Matrix(h5_path, 'y_train').shape[0]\n",
    "samples_per_epoch = int(np.floor(nb_train/batch_size) * batch_size)  # make samples_per_epoch in fit_generator fit\n",
    "\n",
    "# Training model\n",
    "history = model.fit_generator(batch_generator(h5_path, 'X_train', 'y_train', batch_size),\n",
    "                              samples_per_epoch=samples_per_epoch,\n",
    "                              nb_epoch=nb_epoch,\n",
    "                              callbacks=[EarlyStopping(patience=2)],\n",
    "                              validation_data=(HDF5Matrix(h5_path, 'X_val'),\n",
    "                                               HDF5Matrix(h5_path, 'y_val')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if nb_epoch is not enough, continue training by executing this cell\n",
    "extended_nb_epoch = 1\n",
    "history_ext = model.fit_generator(batch_generator(h5_path, 'X_train', 'y_train', batch_size),\n",
    "                              samples_per_epoch=samples_per_epoch,\n",
    "                              nb_epoch=extended_nb_epoch,\n",
    "                              callbacks=[EarlyStopping(patience=2)],\n",
    "                              validation_data=(HDF5Matrix(h5_path, 'X_val'),\n",
    "                                               HDF5Matrix(h5_path, 'y_val')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export mode for testing in simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('./model.h5')\n",
    "with open('./model.json', 'w') as f:\n",
    "    json.dump(model.to_json(), f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
